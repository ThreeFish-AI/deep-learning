{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**工程完整信息与更多演示：**\n",
    "- 博主个人主页：[三余知行官方网站](https://threefish.site/trend)\n",
    "- GitHub Repo：[ThreeFish-AI/deep-learning](https://github.com/ThreeFish-AI/deep-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numerical_gradient_1d(f, x):\n",
    "    \"\"\"梯度函数\n",
    "    用数值微分求导法，求 f 关于 1 组参数的 1 个梯度。\n",
    "\n",
    "    Args:\n",
    "        f: 损失函数\n",
    "        x: 参数（1 组参数，1 维数组）\n",
    "    Returns:\n",
    "        grad: 1 组梯度（1 维数组）\n",
    "    \"\"\"\n",
    "    h = 1e-4                    # 0.0001\n",
    "    grad = np.zeros_like(x)     # 生成和 x 形状相同的数组，用于存放梯度（所有变量的偏导数）\n",
    "\n",
    "    for idx in range(x.size):   # 挨个遍历所有变量\n",
    "        xi = x[idx]             # 取第 idx 个变量\n",
    "        x[idx] = float(xi) + h\n",
    "        fxh1 = f(x)             # 求第 idx 个变量增大 h 所得计算结果\n",
    "\n",
    "        x[idx] = xi - h\n",
    "        fxh2 = f(x)             # 求第 idx 个变量减小 h 所得计算结果\n",
    "\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)  # 求第 idx 个变量的偏导数\n",
    "        x[idx] = xi             # 还原第 idx 个变量的值\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(w):\n",
    "    \"\"\"损失函数\n",
    "    Args:\n",
    "        w0: 参数 w0\n",
    "        w1: 参数 w1\n",
    "    Returns:\n",
    "        损失值\n",
    "    \"\"\"\n",
    "    return w[0]**2 + w[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: w = [-2.4  3.2], loss = 15.99999999999875\n",
      "Iteration 10: w = [-0.25769804  0.34359738], loss = 0.18446744073649915\n",
      "Iteration 20: w = [-0.02767012  0.03689349], loss = 0.0021267647932494446\n",
      "Iteration 30: w = [-0.00297106  0.00396141], loss = 2.4519928653780434e-05\n",
      "Iteration 40: w = [-0.00031901  0.00042535], loss = 2.8269553036369085e-07\n",
      "Iteration 50: w = [-3.42539446e-05  4.56719262e-05], loss = 3.2592575621253703e-09\n",
      "Iteration 60: w = [-3.67798930e-06  4.90398573e-06], loss = 3.7576681324268233e-11\n",
      "Iteration 70: w = [-3.94921094e-07  5.26561458e-07], loss = 4.3322963970507253e-13\n",
      "Iteration 80: w = [-4.24043296e-08  5.65391061e-08], loss = 4.994797680490399e-15\n",
      "Iteration 90: w = [-4.55313022e-09  6.07084029e-09], loss = 5.758609657000494e-17\n",
      "Final parameters: [-6.11110793e-10  8.14814391e-10]\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(initial_w, learning_rate=0.1, num_iterations=100):\n",
    "    \"\"\"梯度下降法\n",
    "    Args:\n",
    "        initial_w: 初始参数\n",
    "        learning_rate: 学习率\n",
    "        num_iterations: 迭代次数\n",
    "    \"\"\"\n",
    "    w = initial_w\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        grad = numerical_gradient_1d(loss_function, w)      # 计算梯度\n",
    "        w -= learning_rate * grad                           # 更新参数\n",
    "\n",
    "        # 打印当前损失值\n",
    "        if i % 10 == 0:                                   # 每 10 次打印一次\n",
    "            print(f\"Iteration {i}: w = {w}, loss = {loss_function(w)}\")\n",
    "\n",
    "    return w\n",
    "\n",
    "# 随机初始化 w0 = -3.0, w1 = 4.0\n",
    "init_w = np.array([-3.0, 4.0])\n",
    "final_w = gradient_descent(init_w)\n",
    "\n",
    "print(f\"Final parameters: {final_w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**工程完整信息与更多演示：**\n",
    "- 博主个人主页：[三余知行官方网站](https://threefish.site/trend)\n",
    "- GitHub Repo：[ThreeFish-AI/deep-learning](https://github.com/ThreeFish-AI/deep-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
