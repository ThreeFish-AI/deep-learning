{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**工程完整信息与更多演示：**\n",
    "- 博主个人主页：[三余知行官方网站](https://threefish.site/trend)\n",
    "- GitHub Repo：[ThreeFish-AI/deep-learning](https://github.com/ThreeFish-AI/deep-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "前置准备："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "print(mnist.keys())\n",
    "# dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n",
      "5\n",
      "(1, 784)\n"
     ]
    }
   ],
   "source": [
    "### 查看数据集\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "print(X.shape)\n",
    "# (70000, 784)\n",
    "\n",
    "print(y.shape)\n",
    "# (70000,)\n",
    "\n",
    "print(y[:1][0])\n",
    "# 5\n",
    "\n",
    "print(X[:1].shape)\n",
    "# (1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "some_digit = X[:1].to_numpy()\n",
    "plot_digit(some_digit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, t_train, t_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集输入数据的形状： (60000, 784)\n",
      "训练集输出标签的形状： (60000,)\n",
      "测试集输入数据的形状： (10000, 784)\n",
      "测试集输出标签的形状： (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('训练集输入数据的形状：', x_train.shape)    # (60000, 784)\n",
    "print('训练集输出标签的形状：', t_train.shape)    # (60000,)\n",
    "print('测试集输入数据的形状：', x_test.shape)     # (10000, 784)\n",
    "print('测试集输出标签的形状：', t_test.shape)     # (10000,)\n",
    "\n",
    "# 训练集输入数据的形状： (60000, 784)\n",
    "# 训练集输出标签的形状： (60000,)\n",
    "# 测试集输入数据的形状： (10000, 784)\n",
    "# 测试集输出标签的形状： (10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推理过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cm.huang/Documents/workspace/projects/aurelius/deep-learning/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle\n",
    "\n",
    "# 初始化并训练神经网络模型\n",
    "# hidden_layer_sizes=(50, 100) 表示第 1 层 50 个神经元，第 2 层 100 个神经元\n",
    "# max_iter=20 表示最大迭代次数为 20\n",
    "# random_state=42 表示随机种子为 42\n",
    "model = MLPClassifier(hidden_layer_sizes=(50, 100), max_iter=20, random_state=42)\n",
    "# fit 表示训练模型，得到“最佳”的权重参数\n",
    "model.fit(x_train, t_train)\n",
    "\n",
    "# 保存模型的样本权重\n",
    "weight_params = model.coefs_\n",
    "bias_params = model.intercepts_\n",
    "\n",
    "W = {'W'+str(i+1): weight_params[i] for i in range(len(weight_params))}\n",
    "B = {'b'+str(i+1): bias_params[i] for i in range(len(bias_params))}\n",
    "network = {**W, **B}\n",
    "\n",
    "with open('sample_weight.pkl', 'wb') as f:\n",
    "    pickle.dump(network, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 shape: (784, 50)\n",
      "W2 shape: (50, 100)\n",
      "W3 shape: (100, 10)\n",
      "b1 shape: (50,)\n",
      "b2 shape: (100,)\n",
      "b3 shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def init_network(model_file='sample_weight.pkl'):\n",
    "    with open(model_file, 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "# 查看模型权重参数\n",
    "network = init_network()\n",
    "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "print('W1 shape:', W1.shape)\n",
    "print('W2 shape:', W2.shape)\n",
    "print('W3 shape:', W3.shape)\n",
    "print('b1 shape:', b1.shape)\n",
    "print('b2 shape:', b2.shape)\n",
    "print('b3 shape:', b3.shape)\n",
    "\n",
    "# 可以看到加载的权重参数形状与上文前向传播中介绍的相符：\n",
    "# W1 shape: (784, 50)\n",
    "# W2 shape: (50, 100)\n",
    "# W3 shape: (100, 10)\n",
    "# b1 shape: (50,)\n",
    "# b2 shape: (100,)\n",
    "# b3 shape: (10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 weights(W1): [[-6.82908655e-134  2.73817863e-124  7.86086298e-131 ... -2.51158996e-136\n",
      "  -1.87750455e-135  6.86738504e-129]\n",
      " [-1.02093698e-123  4.38144943e-130 -1.02999203e-124 ... -2.04415070e-135\n",
      "   2.07573547e-123  3.21365984e-126]\n",
      " [ 7.89668810e-124  1.83923575e-133  3.86927841e-132 ...  2.09755758e-137\n",
      "  -1.63732471e-124  2.42258346e-131]\n",
      " ...\n",
      " [-5.86543224e-136 -7.17964025e-133 -2.61980264e-136 ... -1.45588920e-127\n",
      "   7.93626954e-130 -1.38863587e-129]\n",
      " [ 7.19221960e-134  9.15123409e-127 -1.59973454e-135 ... -9.50850957e-134\n",
      "  -8.63101967e-131  4.52899308e-127]\n",
      " [ 2.21426762e-123 -8.68062610e-138  9.65843942e-134 ...  4.04295961e-127\n",
      "   6.60988568e-132 -2.27081575e-123]]\n",
      "Layer 2 weights(W2): [[-0.07216008  0.03237817 -0.30696488 ... -0.03664662  0.07658222\n",
      "   0.02644618]\n",
      " [ 0.16774598  0.02235196 -0.11842245 ... -0.04932866  0.01448016\n",
      "   0.0207693 ]\n",
      " [-0.11351393  0.15539243  0.00259248 ... -0.18830871 -0.1148917\n",
      "   0.02773119]\n",
      " ...\n",
      " [ 0.06451093  0.02327634 -0.1132122  ... -0.10353967 -0.02715535\n",
      "  -0.16703525]\n",
      " [-0.01537405 -0.04926694 -0.17434954 ...  0.07270678  0.09747531\n",
      "  -0.00617494]\n",
      " [-0.09010675 -0.0677921   0.06192221 ... -0.16570688 -0.19768671\n",
      "  -0.08998851]]\n",
      "Layer 3 weights(W3): [[ 5.22853581e-02 -1.26697444e-01  1.38297075e-01  5.23496136e-02\n",
      "   6.14831421e-02 -3.78902652e-02  1.76143522e-01  5.87658822e-02\n",
      "   1.36045963e-02  1.41049791e-01]\n",
      " [ 1.46511497e-01  3.69564159e-02 -2.27379018e-02 -1.56948114e-01\n",
      "   1.68843039e-01  1.13848556e-01 -7.46913358e-02  1.07567115e-01\n",
      "   9.68389182e-02 -8.43218361e-02]\n",
      " [ 7.77108886e-02 -2.72884650e-01  2.04470500e-02 -1.07680435e-01\n",
      "   1.98314971e-01 -1.31238954e-01 -1.53490538e-01 -1.37986875e-01\n",
      "  -1.68715113e-02 -3.11151626e-02]\n",
      " [ 5.40877783e-02 -4.67376690e-02  8.26486741e-02  1.87378835e-02\n",
      "  -1.02847178e-01 -1.40145158e-01 -4.41615221e-02  3.72240152e-02\n",
      "   8.37151298e-02 -1.47481913e-01]\n",
      " [ 4.35066812e-02 -9.82083040e-02 -5.31242908e-02 -9.36631090e-02\n",
      "   5.55666788e-02  2.29024288e-04  2.32031498e-01 -1.84403020e-01\n",
      "   6.49542795e-02  1.09934842e-01]\n",
      " [-1.44872470e-01 -7.52940058e-02 -1.18177190e-01  2.64870176e-02\n",
      "   7.51464143e-02  6.29293691e-02  7.54160124e-03  1.01783682e-01\n",
      "  -1.12693402e-01  1.83111883e-01]\n",
      " [-7.31354086e-02 -1.08578593e-01  1.32538655e-01  1.13942633e-01\n",
      "   1.25221559e-01 -1.16121178e-01  1.29751078e-01  1.00645390e-01\n",
      "   1.31481776e-01  1.85982620e-01]\n",
      " [-1.47765039e-01  3.96186422e-02  6.31911410e-02 -2.82157532e-02\n",
      "  -1.73242343e-01 -8.36449294e-02 -3.12479673e-02 -2.40964043e-02\n",
      "  -1.34917644e-01 -1.03697226e-01]\n",
      " [-1.12896979e-01 -1.92118163e-01 -9.69368038e-02  1.10714053e-01\n",
      "  -1.94201992e-01  8.95665483e-02  1.17579405e-01 -2.06543218e-02\n",
      "  -1.21432487e-01  1.60888013e-01]\n",
      " [-1.46168737e-01  2.61916874e-02  4.72999815e-02 -5.28517797e-02\n",
      "  -1.74374648e-01 -4.50124894e-02 -1.47516919e-01  6.61772181e-02\n",
      "   6.57821824e-02 -6.78575392e-02]\n",
      " [-8.40483169e-02  1.56767339e-01  5.56316448e-02  3.02978075e-02\n",
      "   9.60826914e-02  1.34181065e-01  5.90532345e-02 -5.57320581e-02\n",
      "  -4.71310836e-02 -3.03539895e-02]\n",
      " [-2.94734527e-02 -8.65487773e-02  2.17187269e-03  4.69481975e-02\n",
      "  -7.54879828e-02  7.55154669e-02  1.99421495e-02  6.77975761e-02\n",
      "  -2.70633991e-02 -5.09951743e-03]\n",
      " [ 8.58764329e-02  1.61938500e-02  3.07061484e-02 -1.03753641e-01\n",
      "   9.80509812e-03  1.43850594e-01 -6.36844612e-02 -1.74874557e-02\n",
      "   9.66506416e-03  6.13607104e-02]\n",
      " [-1.36562555e-01  1.78037120e-01 -1.25708349e-01  9.09667933e-02\n",
      "  -1.09080341e-01 -1.24695754e-01  9.20190403e-02  7.07011294e-02\n",
      "   1.67377654e-01 -8.91247234e-02]\n",
      " [-5.22861971e-02 -1.64371027e-01 -5.34806075e-02 -8.27791067e-02\n",
      "  -1.70585744e-01 -7.47332863e-03 -1.18055718e-01 -4.94626339e-03\n",
      "  -1.18711730e-02 -1.27160434e-01]\n",
      " [ 1.98183559e-01 -4.95834981e-02  1.66636383e-01  1.65684841e-01\n",
      "   8.11619007e-02  1.12200042e-01  5.66848411e-02 -8.21358777e-02\n",
      "   6.78526629e-02 -3.16578555e-02]\n",
      " [ 1.12250518e-01  5.20238597e-02 -9.59969119e-02 -1.55868887e-01\n",
      "  -4.52094009e-02 -4.86833953e-02 -1.07797444e-01  4.83794935e-02\n",
      "   4.04721962e-02 -1.38447571e-01]\n",
      " [ 6.63221184e-02  8.83124958e-02  2.77338005e-02  8.33292829e-02\n",
      "  -1.30446940e-01 -4.27375525e-02  6.04784383e-02 -4.95448398e-02\n",
      "  -5.68201458e-03  7.71173366e-02]\n",
      " [ 6.56382351e-02 -1.72378866e-01  4.23491881e-03 -6.40135095e-02\n",
      "   5.43954707e-02 -1.16755270e-02  5.29254620e-02  8.82333309e-03\n",
      "  -6.04680845e-02 -9.95820628e-02]\n",
      " [-5.67418516e-02 -4.61700361e-02  5.46175247e-02  1.67220022e-02\n",
      "  -8.57162030e-02  9.68186960e-02  1.24919522e-02 -1.08310032e-01\n",
      "  -6.69336725e-02 -2.36798648e-02]\n",
      " [ 2.11315476e-02  1.01612541e-01  2.87550451e-02  1.13753468e-01\n",
      "  -9.85805001e-02  3.17687398e-02  8.37923124e-02 -1.09818357e-01\n",
      "  -5.07115747e-02  4.28701693e-03]\n",
      " [ 1.82834662e-01  1.21207936e-01  7.50666898e-02  2.02886325e-01\n",
      "  -2.75396019e-01 -5.74008728e-02 -3.25523232e-02 -2.06794821e-01\n",
      "  -6.35957484e-02 -2.27408109e-01]\n",
      " [ 1.73729009e-01 -1.91720877e-01  5.03134460e-03  4.56953382e-02\n",
      "  -7.43360057e-02 -1.32953254e-01 -1.09231405e-02 -6.77951265e-02\n",
      "   1.19781615e-01  1.23020184e-02]\n",
      " [ 1.05704969e-01  1.21309503e-01 -9.33451188e-02  8.78734601e-03\n",
      "  -1.21226829e-01 -9.83555053e-02  1.47297959e-01 -4.63014105e-02\n",
      "  -7.00074730e-02 -4.87677650e-02]\n",
      " [-1.21116906e-01  3.46765058e-02 -7.40972826e-02  1.30517386e-02\n",
      "   1.22375666e-01 -7.72489344e-02 -1.40797615e-01 -7.54717452e-02\n",
      "   6.10624833e-02  1.06627475e-02]\n",
      " [ 1.03410170e-01 -5.10196540e-02  8.44114301e-03 -3.80395590e-02\n",
      "  -7.89319726e-02  2.52158490e-02  4.51261198e-02  2.68450844e-02\n",
      "   1.68605114e-01  8.86530992e-02]\n",
      " [ 6.65143938e-02  8.85689563e-02 -1.83073435e-01 -9.82878306e-02\n",
      "  -1.37419498e-01 -1.03043598e-01  1.60242875e-01 -1.07873651e-01\n",
      "   6.36651907e-02  3.26316397e-02]\n",
      " [-8.40728189e-02 -2.84585946e-02  5.44889340e-02 -6.96223253e-02\n",
      "   9.85984903e-02 -1.27412734e-01 -2.06288568e-01 -1.95756316e-03\n",
      "   4.80088157e-02 -1.56049204e-01]\n",
      " [ 1.91074807e-01  1.17928205e-01  1.38414396e-01 -3.25320953e-02\n",
      "  -8.81005739e-03  1.05376431e-01  1.98452898e-01  1.00827825e-01\n",
      "   1.70633084e-01  9.75081363e-02]\n",
      " [-2.48379503e-02 -1.17624401e-01  6.05582976e-06  1.53991410e-01\n",
      "  -2.31580913e-01  9.91185303e-02  1.26635954e-02 -5.20779296e-02\n",
      "  -6.12348397e-02 -1.29338445e-01]\n",
      " [ 8.55918011e-02  5.92877579e-02  1.31886236e-01 -8.90206587e-02\n",
      "  -1.14914925e-01  8.74756620e-02 -2.88728876e-02 -1.68663367e-01\n",
      "  -9.59010701e-02  1.03534489e-02]\n",
      " [-1.07113028e-01  1.20665194e-01  3.22880676e-02  4.95764315e-02\n",
      "   1.37170354e-01 -1.18310387e-01  2.68149168e-02  6.67490614e-02\n",
      "   1.47552200e-01  1.26200493e-01]\n",
      " [ 1.78159117e-03 -1.45480164e-01 -2.82653946e-02  1.18485961e-01\n",
      "   2.19425387e-02  1.73184283e-01 -1.49349738e-01  4.23715236e-02\n",
      "   1.12286919e-01  1.23711069e-01]\n",
      " [ 1.07656382e-02 -9.72962838e-02  9.64722932e-02 -1.43966810e-01\n",
      "   7.71953037e-03 -2.39123669e-02 -1.34257806e-01 -5.15343252e-02\n",
      "   1.40060661e-02 -7.23526112e-03]\n",
      " [-1.73590990e-02  9.39089448e-02  2.03914986e-01  1.30934854e-01\n",
      "   1.52319101e-01  1.71278782e-01  1.50164151e-01  2.02745237e-01\n",
      "   1.13307781e-01  1.00421150e-01]\n",
      " [ 5.55398936e-02  1.86704683e-01  8.18171764e-02  1.00242540e-01\n",
      "  -8.89725566e-02  1.50191064e-01  4.01525874e-02 -1.30398946e-01\n",
      "   1.08123145e-01 -6.10102460e-02]\n",
      " [-1.04420572e-01 -8.64687855e-02 -1.26896029e-01 -1.20964599e-01\n",
      "  -1.79760279e-02  8.67322454e-02 -8.42932671e-03  2.90707759e-02\n",
      "   1.04916460e-01 -6.89651662e-02]\n",
      " [-1.96601431e-02 -2.53283320e-02  4.67196869e-02 -6.98390671e-03\n",
      "   1.13303386e-01 -1.42553057e-01  4.49866494e-02 -3.73672355e-02\n",
      "  -9.23873468e-03 -2.53855288e-02]\n",
      " [-6.34100938e-02 -1.43532521e-01 -8.89327387e-02 -4.05933949e-03\n",
      "  -1.08086334e-01  5.75709328e-02  8.51312891e-02 -7.02030365e-02\n",
      "  -8.42547344e-02  6.13913661e-02]\n",
      " [ 8.09347134e-02 -4.76952144e-02  4.16277032e-02  1.23929683e-01\n",
      "  -6.33327990e-02  4.22921717e-02 -7.30457558e-02 -1.47553019e-01\n",
      "  -4.78051151e-02  3.02662196e-02]\n",
      " [-8.13618544e-02 -2.61789470e-02  2.40598471e-02 -7.56249157e-02\n",
      "  -8.01394864e-02  1.47201816e-02 -1.40586697e-01  1.35513362e-01\n",
      "  -2.20177174e-01  6.64620372e-02]\n",
      " [-5.15802041e-03  1.31038280e-01  1.17834457e-01 -1.27632497e-01\n",
      "   8.18981135e-02 -1.29931931e-01 -1.62054477e-01  1.61023797e-01\n",
      "  -1.28853660e-01 -9.47641029e-02]\n",
      " [-1.38074421e-01 -2.45969259e-03  1.63347547e-01 -7.13819222e-02\n",
      "   1.11508317e-02 -4.01630012e-02 -7.06601132e-02 -3.47338718e-03\n",
      "  -6.27035393e-03 -5.08467075e-02]\n",
      " [ 1.30481118e-01 -3.95800087e-02 -1.43838190e-01  2.02580831e-01\n",
      "   9.98109600e-03  9.32704951e-02  5.51723573e-02 -1.64881834e-02\n",
      "   1.85490298e-03 -1.65642894e-01]\n",
      " [ 9.88829777e-02  6.20701916e-03  1.73538975e-01  7.43697240e-02\n",
      "  -9.81426868e-02 -9.26242730e-04 -1.52338403e-01  9.87551053e-02\n",
      "  -8.45327031e-03 -3.06220167e-02]\n",
      " [ 1.15106777e-01  2.24428318e-01  1.49849250e-01  5.86630072e-03\n",
      "   1.10828204e-01  1.46273342e-01  7.73276699e-02 -3.49713244e-02\n",
      "   1.45217485e-01  1.07783539e-01]\n",
      " [ 4.24638738e-02  2.46616798e-02 -1.06836705e-01 -1.46598252e-03\n",
      "   1.23343523e-02 -6.36124747e-02 -2.03876116e-01 -1.47871400e-01\n",
      "  -2.11365964e-02 -1.28442194e-01]\n",
      " [ 5.76041190e-02 -4.35973801e-02  1.00955120e-01  1.23765403e-01\n",
      "  -1.09473330e-01  1.51656523e-01  1.07941506e-01  5.00838669e-02\n",
      "   1.78322306e-01 -4.67680232e-02]\n",
      " [-7.80407951e-02 -9.26308908e-02 -2.98977978e-02 -4.11985029e-02\n",
      "  -1.48135541e-02 -2.32538239e-01 -5.07261520e-02 -6.85471999e-02\n",
      "  -2.02321185e-01 -1.33628043e-01]\n",
      " [ 1.25474289e-01 -2.02979959e-01 -1.24303876e-01 -1.18768135e-01\n",
      "   5.79458841e-02  1.14789900e-01 -1.91201329e-02  3.23209539e-02\n",
      "   1.69225937e-01 -1.27863691e-01]\n",
      " [ 1.80688314e-01 -1.90711473e-03  1.82829666e-01  5.44744587e-02\n",
      "  -1.14212171e-01  1.88634368e-01 -9.21519379e-02  1.47014295e-01\n",
      "  -8.43550358e-02  8.40594340e-02]\n",
      " [-6.51745235e-02  1.55634004e-01 -9.60931999e-02 -2.81995901e-02\n",
      "   1.64682333e-02  1.67640914e-01  4.76920395e-02 -1.28289489e-02\n",
      "  -2.03276690e-02 -6.65967845e-02]\n",
      " [ 1.07371739e-01 -1.21902270e-01  1.94810130e-02  2.84257845e-02\n",
      "  -9.97389267e-02 -3.93366115e-03  1.08806074e-01  1.56341519e-03\n",
      "  -8.96993148e-02 -2.15266783e-01]\n",
      " [ 6.38240245e-02 -1.26430940e-01  1.42672184e-01  7.64175444e-02\n",
      "  -2.68913744e-02  1.06360195e-01  1.59493751e-02  5.99496767e-02\n",
      "   6.32400723e-03 -5.09691061e-02]\n",
      " [ 9.77623819e-02  1.20815467e-01  1.22849303e-01  1.63851611e-01\n",
      "   5.36817797e-02  2.40850461e-02  3.48052255e-02  1.27869521e-01\n",
      "   1.11301104e-01  1.81771806e-01]\n",
      " [-1.20040197e-01 -1.84028619e-02 -1.11985391e-01 -5.20367896e-02\n",
      "  -1.98809533e-01 -1.38913633e-01 -6.67673848e-02 -9.10667418e-02\n",
      "  -9.81813901e-02 -1.28707944e-01]\n",
      " [ 7.85200841e-02 -3.04428851e-02  8.41216834e-02 -4.58844975e-02\n",
      "   9.00450092e-02 -1.50627895e-01 -6.18762387e-02  7.24761878e-02\n",
      "   1.29091018e-01 -6.82217479e-02]\n",
      " [-8.98642656e-02  1.34627130e-01 -4.95269271e-02 -3.23356824e-02\n",
      "   8.88235051e-02  4.42117126e-02 -3.01656684e-02  9.42262590e-02\n",
      "   3.92351137e-02 -7.26406693e-02]\n",
      " [ 8.01026944e-02  5.10038715e-02  6.90347297e-02  2.38427363e-01\n",
      "  -1.61119731e-01  7.12074011e-02  2.91070566e-02 -7.89832585e-02\n",
      "   4.12811666e-02  3.92972199e-02]\n",
      " [ 1.19844308e-01  1.35036362e-01  2.87922977e-02 -7.83664439e-02\n",
      "   6.09805352e-03 -2.24048982e-02 -5.22274384e-02  2.29734273e-02\n",
      "   6.13440845e-02  6.40870456e-02]\n",
      " [ 1.87371411e-01 -7.69179777e-02 -5.16418505e-02  8.16755043e-02\n",
      "   3.84364677e-03 -7.18997228e-02 -2.16123095e-02 -1.85117398e-02\n",
      "   1.05648542e-01  9.84131866e-02]\n",
      " [-7.83901737e-02 -1.79972098e-01 -1.10342076e-01 -1.35958895e-01\n",
      "  -1.09644314e-01 -8.99636987e-02 -3.84878349e-02 -9.56434263e-02\n",
      "   7.40883170e-04 -8.17866127e-02]\n",
      " [ 1.11958743e-01  1.74539389e-01 -2.95147198e-02 -1.61904246e-01\n",
      "  -1.02175916e-01 -1.53800110e-01 -7.96322752e-02  1.40033085e-02\n",
      "  -6.68084241e-03 -1.09039964e-01]\n",
      " [ 1.14075415e-01 -1.38543161e-01 -1.10211462e-01  3.97430198e-02\n",
      "  -8.83732251e-02  5.63658775e-02  1.99603238e-01  1.52786054e-01\n",
      "  -1.14475232e-01 -7.82018033e-03]\n",
      " [-2.12353424e-03  9.10039853e-02  1.16866175e-01 -4.62514212e-02\n",
      "   1.74927769e-01 -1.75691669e-01  5.97833552e-02  1.77713770e-02\n",
      "  -6.13149125e-02  1.34142692e-01]\n",
      " [-3.64821452e-03  1.19585671e-01  1.77456246e-01  1.17783337e-01\n",
      "  -6.16975253e-02  3.32020494e-02  2.60237572e-02  1.63142736e-01\n",
      "  -4.78889787e-02  1.65310119e-02]\n",
      " [ 1.10627433e-01  7.57937988e-02  1.61851235e-01 -1.02361684e-01\n",
      "  -5.47273046e-02 -2.62462030e-02 -4.98926614e-02 -3.96135717e-02\n",
      "  -9.31568659e-02  7.33552515e-02]\n",
      " [ 1.23450175e-01 -2.11075907e-01 -6.03090842e-02 -8.64961559e-02\n",
      "   1.18522257e-02  5.45244309e-02 -9.63065258e-02  2.50514078e-02\n",
      "  -9.96176672e-02  7.25563328e-02]\n",
      " [ 1.45657073e-01  9.47650340e-02 -7.04396753e-02 -1.14709006e-01\n",
      "  -6.92119726e-02 -3.11370858e-02 -8.00171391e-02  2.43580462e-02\n",
      "   1.90762514e-02 -2.45663827e-02]\n",
      " [ 7.68562300e-03  6.07902089e-02 -9.78035936e-02 -1.00551390e-01\n",
      "   2.75625699e-01  4.60934513e-02  1.68844458e-01  1.05867462e-02\n",
      "   2.75148663e-02  4.52555920e-02]\n",
      " [-1.93214476e-01  4.18972700e-02 -1.24598407e-01 -2.54585816e-02\n",
      "  -1.00287139e-01 -1.40232271e-01 -1.54047353e-01 -8.50066936e-02\n",
      "  -1.57118357e-01  1.09234397e-01]\n",
      " [-7.56038633e-02 -2.51541791e-02 -2.01654469e-01 -1.37155047e-01\n",
      "   1.05409387e-01  1.21323890e-01  7.70130259e-02 -6.69262728e-02\n",
      "  -1.05104995e-01 -9.88754729e-02]\n",
      " [ 3.61103655e-02  1.45135010e-01  1.55719581e-01 -3.02055168e-02\n",
      "  -4.27290136e-02 -1.15597123e-01  9.73851929e-02 -7.18430378e-02\n",
      "  -8.21189851e-03  1.56514611e-01]\n",
      " [ 1.23476712e-01 -1.20357640e-01 -3.84803180e-02  1.08264900e-01\n",
      "   1.14259138e-02  1.10993873e-01  9.30412494e-02  7.15048160e-02\n",
      "   8.31428495e-02  1.35612485e-01]\n",
      " [-6.82509342e-02 -6.74927825e-02 -1.30652919e-01  1.34752522e-01\n",
      "  -9.78526451e-02 -1.21980946e-01 -1.23241461e-01  1.15385758e-01\n",
      "   1.48058267e-01  1.34367841e-01]\n",
      " [ 5.71613863e-03  1.50927376e-01 -1.18337739e-01  7.43248071e-02\n",
      "  -5.54659735e-02 -1.95420154e-02 -1.47640738e-01 -1.86565591e-01\n",
      "  -3.96317529e-02 -1.39280637e-01]\n",
      " [ 2.91249057e-02 -1.23822832e-01 -8.13962237e-02  1.63513035e-01\n",
      "   1.53534086e-01  1.65810904e-01  7.86930808e-02  1.34614941e-01\n",
      "   1.24315035e-01  7.93955529e-02]\n",
      " [-9.74078675e-02 -8.48595935e-02 -8.38643357e-02  6.31525227e-02\n",
      "   1.80049363e-02  3.54316877e-03 -1.47276245e-01 -2.08723156e-01\n",
      "   5.99644632e-02  4.71521505e-02]\n",
      " [-4.77241095e-02 -5.54907624e-02  5.08326054e-02  1.75783539e-01\n",
      "   1.67899130e-01 -1.58030331e-01 -2.59670930e-03 -4.28213493e-02\n",
      "   5.24465893e-03  4.44256966e-02]\n",
      " [-5.14684149e-02  1.57574894e-01 -5.50400258e-03  1.50733410e-01\n",
      "  -9.63605209e-02 -3.22182668e-02  3.08505588e-02  5.94979190e-02\n",
      "   5.97776698e-02  1.88483424e-01]\n",
      " [-2.90481291e-02 -1.93829972e-02  1.50609360e-01  2.45696955e-02\n",
      "  -2.91678599e-02  8.41953150e-02  5.40340595e-02 -6.00064029e-02\n",
      "  -7.20778563e-02 -4.67817364e-02]\n",
      " [-1.65730137e-01  1.31257210e-01 -8.59869382e-02 -6.48532348e-02\n",
      "   3.99363907e-03  9.27005416e-02  1.05938315e-01 -1.94956254e-02\n",
      "   1.24805655e-01  1.04144395e-02]\n",
      " [-4.97765025e-02  7.69582816e-02  1.41910651e-02  8.65342258e-02\n",
      "   1.16678936e-01  1.29458887e-01 -5.46999698e-02  2.13694195e-01\n",
      "   5.01249458e-02  1.25723033e-02]\n",
      " [-4.54867653e-02  1.32700469e-01  1.02083017e-02 -6.60981156e-02\n",
      "   6.83284258e-02 -1.77905508e-01 -9.19453009e-02  1.32534761e-01\n",
      "  -2.32690730e-02  1.15664011e-01]\n",
      " [ 4.90591508e-02  1.65641958e-02 -5.97315876e-02  1.18002214e-01\n",
      "   7.26653176e-02  4.02610190e-04 -2.66352654e-02 -6.78272981e-02\n",
      "   1.05988993e-01  4.14563050e-02]\n",
      " [-1.06344840e-01  8.13894777e-02  1.47055720e-01 -1.24837797e-01\n",
      "   1.17397288e-01  1.57385907e-01  2.20716064e-01 -8.75818544e-02\n",
      "  -5.58421097e-03  1.65295710e-01]\n",
      " [-1.71277379e-01  1.80154662e-03 -5.08770162e-03  5.72970823e-02\n",
      "  -7.34208426e-02  1.39852486e-01 -8.05927927e-02  8.31630457e-02\n",
      "   1.24800261e-02 -1.05912905e-01]\n",
      " [-6.75108676e-02  1.08409416e-01  4.28727944e-02  4.15275154e-02\n",
      "   5.39825004e-02 -1.02706162e-01  6.70662427e-02  4.67989470e-04\n",
      "   8.52443072e-02 -9.07441389e-02]\n",
      " [ 1.53777901e-01  4.34831957e-02 -1.21990723e-01  1.38534792e-02\n",
      "  -7.45723090e-02  1.00863958e-01 -1.45850207e-01  1.52635793e-02\n",
      "  -1.59768874e-02  6.62004787e-02]\n",
      " [ 1.85560827e-02 -1.85990331e-01  5.70630211e-02  1.57321302e-01\n",
      "   2.06834009e-02 -6.98735844e-02  1.63742460e-02 -1.44564384e-01\n",
      "  -5.55397589e-02 -2.52274718e-02]\n",
      " [ 1.15353764e-01  8.59162775e-02  7.62881659e-02 -1.19979228e-01\n",
      "   5.70170988e-02 -3.28139245e-02  2.68451959e-02  6.93111937e-02\n",
      "  -7.99699948e-02 -1.33649317e-01]\n",
      " [ 7.17836194e-03 -2.76678287e-02 -2.03436512e-03 -8.67193301e-03\n",
      "   2.31147130e-01  1.37237360e-01  2.10060604e-01  1.03695608e-01\n",
      "   1.45155597e-01  1.12881877e-01]\n",
      " [ 1.52318472e-01  6.56658901e-02  1.25272904e-01 -8.39415241e-02\n",
      "   1.44435815e-01  8.62055998e-02  8.09486539e-02 -5.17482113e-02\n",
      "   5.37042492e-02  7.47315625e-02]\n",
      " [ 8.25272560e-02  1.80381696e-02 -1.95285848e-02  1.35982311e-01\n",
      "   1.23325035e-01 -3.10384634e-02  1.25888984e-01 -5.51759686e-02\n",
      "  -1.19720085e-01  9.10800266e-02]\n",
      " [ 1.13809528e-01  4.62766781e-02 -5.20710852e-02 -7.38337531e-02\n",
      "   7.21749707e-02  4.25771950e-02 -2.52844573e-02 -7.16198404e-04\n",
      "  -5.90062542e-02  2.16288686e-01]\n",
      " [-4.17741025e-02 -1.45200758e-02  6.77500459e-02 -9.67937569e-02\n",
      "  -6.22753381e-02 -8.00150262e-03  2.59162197e-02  7.65189632e-02\n",
      "   8.01629889e-03 -9.52471286e-02]\n",
      " [-1.53044152e-01 -5.76784725e-02 -6.63513882e-02  7.11468031e-02\n",
      "   2.15476499e-01  1.67480842e-01  3.78033019e-02  1.18042872e-01\n",
      "   1.71164149e-01  7.70409095e-02]\n",
      " [ 4.25874962e-02 -6.46911677e-02 -1.20733878e-01  1.35871040e-02\n",
      "   1.91283663e-01  2.72369555e-02 -1.37555760e-01  6.10893311e-02\n",
      "   3.30277862e-03  1.58114142e-01]\n",
      " [-1.30516096e-01  8.73854707e-02  7.95695567e-02  1.57632731e-01\n",
      "  -8.09863525e-03  8.62484165e-02 -1.47731559e-01 -7.32676939e-02\n",
      "  -1.22589505e-02  3.90204050e-02]\n",
      " [-8.91916586e-03 -1.11147917e-01  1.88880477e-02  4.07215673e-02\n",
      "   6.97409219e-02 -1.20880403e-01  9.25973067e-02 -1.02178502e-03\n",
      "  -4.18847549e-02  3.56570368e-02]]\n",
      "Layer 1 biases(b1): [ 0.0137522   0.03833063 -0.09956145 -0.03856783 -0.03449078 -0.04400879\n",
      " -0.09198647 -0.11015921 -0.09493111  0.03857582  0.00786484 -0.04100733\n",
      "  0.00383071 -0.12378986 -0.05809759 -0.0653058   0.05109125 -0.07841093\n",
      " -0.0255141  -0.09353002 -0.08269556 -0.0269298  -0.02812359 -0.02050459\n",
      "  0.01194842 -0.22781834 -0.09562882  0.01556877 -0.09116892 -0.0735788\n",
      " -0.10579535  0.03210905  0.03644254 -0.08821678  0.22158669  0.01785743\n",
      " -0.14960641 -0.07398911  0.03043871 -0.02675142 -0.06899549  0.18304038\n",
      " -0.11450301  0.02820933 -0.11269283 -0.08658433 -0.04010245 -0.02471031\n",
      "  0.02431987 -0.02043312]\n",
      "Layer 2 biases(b2): [ 0.04761845  0.0097227  -0.18579688  0.33545441 -0.00251954 -0.28249027\n",
      "  0.32205059  0.0535535  -0.14486496  0.0632555   0.15319932 -0.30925672\n",
      "  0.19008791 -0.04105189 -0.37384366  0.2087878  -0.19774662  0.02288015\n",
      " -0.23427175 -0.02497164 -0.25163439  0.91014371  0.09471953 -0.05406664\n",
      " -0.07312411  0.14334646  0.00784481 -0.0242393   0.15511199  0.80763787\n",
      " -0.16527127 -0.00492468 -0.33917483  0.28148216 -0.11863069  0.13612558\n",
      " -0.01473422 -0.01767065  0.13356408 -0.15851431 -0.28401377 -0.24980915\n",
      "  0.04233325  0.27704843 -0.07767159 -0.33715487  0.05670558  0.30044942\n",
      "  0.04872077 -0.26865378 -0.29132482 -0.51337898 -0.13545903  0.03437958\n",
      " -0.11185014 -0.06470243  0.4049189  -0.53920557  0.22352117 -0.06131408\n",
      "  0.18788468  0.36311069  0.08489019 -0.07573443 -0.28437569 -0.54613697\n",
      " -0.19329358 -0.01204985 -0.32474467 -0.0814863  -0.15213831 -0.1401366\n",
      " -0.00568449 -0.22133075  0.21051545  0.18279323 -0.24675207 -0.00417554\n",
      " -0.15289677 -0.13168078 -0.16166051  0.07690279 -0.05726844 -0.41906907\n",
      "  0.19818121 -0.06457938 -0.34873833 -0.0315622   0.02884793  0.44842607\n",
      " -0.49964931 -0.26406381  0.00877412  0.19862937 -0.47000536 -0.03562795\n",
      "  0.08788668 -0.29752006 -0.39022158 -0.14474585]\n",
      "Layer 3 biases(b3): [ 0.05053622 -0.37941181  0.13039122  0.11149158  0.07131728 -0.24897518\n",
      " -0.13914605 -0.51744395  0.53103882 -0.21369341]\n"
     ]
    }
   ],
   "source": [
    "# 查看模型的权重参数\n",
    "print('Layer 1 weights(W1):', W1)\n",
    "print('Layer 2 weights(W2):', W2)\n",
    "print('Layer 3 weights(W3):', W3)\n",
    "print('Layer 1 biases(b1):', b1)\n",
    "print('Layer 2 biases(b2):', b2)\n",
    "print('Layer 3 biases(b3):', b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推理与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率: 0.9499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.95      0.95      1032\n",
      "           3       0.93      0.93      0.93      1010\n",
      "           4       0.97      0.92      0.94       982\n",
      "           5       0.95      0.93      0.94       892\n",
      "           6       0.97      0.96      0.96       958\n",
      "           7       0.97      0.94      0.96      1028\n",
      "           8       0.91      0.95      0.93       974\n",
      "           9       0.91      0.95      0.93      1009\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 用于评估模型的表现\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 进行推理（只取测试集进行推理效果测试，暂时丢弃训练集）\n",
    "t_pred = model.predict(x_test)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"准确率: {accuracy_score(t_test, t_pred)}\")\n",
    "print(classification_report(t_test, t_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 10000\n",
      "Sample 8 - Predicted: 6, Actual: 5\n",
      "Sample 63 - Predicted: 2, Actual: 3\n",
      "Sample 111 - Predicted: 1, Actual: 7\n",
      "Sample 115 - Predicted: 9, Actual: 4\n",
      "Sample 130 - Predicted: 5, Actual: 6\n",
      "Sample 149 - Predicted: 9, Actual: 2\n",
      "Sample 151 - Predicted: 8, Actual: 9\n",
      "Sample 195 - Predicted: 9, Actual: 3\n",
      "Sample 211 - Predicted: 9, Actual: 5\n",
      "Sample 241 - Predicted: 3, Actual: 9\n",
      "Sample 247 - Predicted: 2, Actual: 4\n",
      "Sample 250 - Predicted: 9, Actual: 4\n",
      "Sample 259 - Predicted: 0, Actual: 6\n",
      "Sample 287 - Predicted: 2, Actual: 4\n",
      "Sample 315 - Predicted: 3, Actual: 9\n",
      "Sample 320 - Predicted: 1, Actual: 9\n",
      "Sample 321 - Predicted: 7, Actual: 2\n",
      "Sample 340 - Predicted: 3, Actual: 5\n",
      "Sample 352 - Predicted: 0, Actual: 5\n",
      "Sample 376 - Predicted: 9, Actual: 4\n",
      "Sample 421 - Predicted: 3, Actual: 2\n",
      "Sample 432 - Predicted: 5, Actual: 4\n",
      "Sample 445 - Predicted: 0, Actual: 6\n",
      "Sample 447 - Predicted: 9, Actual: 4\n",
      "Sample 450 - Predicted: 5, Actual: 3\n",
      "Sample 507 - Predicted: 9, Actual: 3\n",
      "Sample 522 - Predicted: 3, Actual: 7\n",
      "Sample 543 - Predicted: 3, Actual: 8\n",
      "Sample 552 - Predicted: 8, Actual: 0\n",
      "Sample 571 - Predicted: 9, Actual: 4\n",
      "Sample 582 - Predicted: 2, Actual: 8\n",
      "Sample 583 - Predicted: 3, Actual: 2\n",
      "Sample 610 - Predicted: 2, Actual: 4\n",
      "Sample 613 - Predicted: 8, Actual: 2\n",
      "Sample 619 - Predicted: 8, Actual: 1\n",
      "Sample 638 - Predicted: 7, Actual: 5\n",
      "Sample 691 - Predicted: 9, Actual: 8\n",
      "Sample 707 - Predicted: 9, Actual: 4\n",
      "Sample 711 - Predicted: 8, Actual: 5\n",
      "Sample 717 - Predicted: 6, Actual: 0\n",
      "Sample 720 - Predicted: 8, Actual: 5\n",
      "Sample 726 - Predicted: 9, Actual: 7\n",
      "Sample 728 - Predicted: 3, Actual: 2\n",
      "Sample 740 - Predicted: 9, Actual: 4\n",
      "Sample 748 - Predicted: 9, Actual: 4\n",
      "Sample 760 - Predicted: 9, Actual: 4\n",
      "Sample 774 - Predicted: 9, Actual: 4\n",
      "Sample 810 - Predicted: 8, Actual: 7\n",
      "Sample 839 - Predicted: 3, Actual: 8\n",
      "Sample 877 - Predicted: 5, Actual: 8\n",
      "Sample 881 - Predicted: 9, Actual: 4\n",
      "Sample 885 - Predicted: 2, Actual: 6\n",
      "Sample 900 - Predicted: 3, Actual: 1\n",
      "Sample 938 - Predicted: 5, Actual: 3\n",
      "Sample 939 - Predicted: 0, Actual: 2\n",
      "Sample 951 - Predicted: 9, Actual: 5\n",
      "Sample 956 - Predicted: 3, Actual: 1\n",
      "Sample 957 - Predicted: 5, Actual: 3\n",
      "Sample 965 - Predicted: 0, Actual: 6\n",
      "Sample 975 - Predicted: 3, Actual: 2\n",
      "Sample 1002 - Predicted: 3, Actual: 2\n",
      "Sample 1010 - Predicted: 9, Actual: 4\n",
      "Sample 1014 - Predicted: 5, Actual: 6\n",
      "Sample 1039 - Predicted: 4, Actual: 7\n",
      "Sample 1055 - Predicted: 9, Actual: 7\n",
      "Sample 1062 - Predicted: 9, Actual: 3\n",
      "Sample 1092 - Predicted: 2, Actual: 3\n",
      "Sample 1112 - Predicted: 6, Actual: 4\n",
      "Sample 1114 - Predicted: 8, Actual: 3\n",
      "Sample 1147 - Predicted: 7, Actual: 4\n",
      "Sample 1156 - Predicted: 8, Actual: 7\n",
      "Sample 1159 - Predicted: 2, Actual: 4\n",
      "Sample 1161 - Predicted: 8, Actual: 6\n",
      "Sample 1166 - Predicted: 2, Actual: 3\n",
      "Sample 1173 - Predicted: 9, Actual: 7\n",
      "Sample 1181 - Predicted: 8, Actual: 6\n",
      "Sample 1182 - Predicted: 5, Actual: 6\n",
      "Sample 1191 - Predicted: 6, Actual: 0\n",
      "Sample 1192 - Predicted: 8, Actual: 9\n",
      "Sample 1194 - Predicted: 3, Actual: 7\n",
      "Sample 1209 - Predicted: 8, Actual: 6\n",
      "Sample 1226 - Predicted: 2, Actual: 7\n",
      "Sample 1232 - Predicted: 4, Actual: 9\n",
      "Sample 1239 - Predicted: 5, Actual: 3\n",
      "Sample 1242 - Predicted: 9, Actual: 4\n",
      "Sample 1247 - Predicted: 0, Actual: 9\n",
      "Sample 1256 - Predicted: 3, Actual: 2\n",
      "Sample 1260 - Predicted: 1, Actual: 7\n",
      "Sample 1283 - Predicted: 2, Actual: 7\n",
      "Sample 1289 - Predicted: 9, Actual: 5\n",
      "Sample 1290 - Predicted: 5, Actual: 3\n",
      "Sample 1299 - Predicted: 7, Actual: 5\n",
      "Sample 1326 - Predicted: 1, Actual: 7\n",
      "Sample 1328 - Predicted: 9, Actual: 7\n",
      "Sample 1364 - Predicted: 2, Actual: 8\n",
      "Sample 1378 - Predicted: 8, Actual: 5\n",
      "Sample 1393 - Predicted: 3, Actual: 5\n",
      "Sample 1409 - Predicted: 3, Actual: 2\n",
      "Sample 1413 - Predicted: 9, Actual: 4\n",
      "Sample 1453 - Predicted: 9, Actual: 4\n",
      "Sample 1463 - Predicted: 7, Actual: 3\n",
      "Sample 1494 - Predicted: 0, Actual: 7\n",
      "Sample 1500 - Predicted: 1, Actual: 7\n",
      "Sample 1522 - Predicted: 9, Actual: 7\n",
      "Sample 1525 - Predicted: 0, Actual: 5\n",
      "Sample 1527 - Predicted: 3, Actual: 1\n",
      "Sample 1530 - Predicted: 7, Actual: 8\n",
      "Sample 1549 - Predicted: 6, Actual: 4\n",
      "Sample 1553 - Predicted: 3, Actual: 9\n",
      "Sample 1554 - Predicted: 8, Actual: 9\n",
      "Sample 1581 - Predicted: 9, Actual: 7\n",
      "Sample 1607 - Predicted: 5, Actual: 3\n",
      "Sample 1609 - Predicted: 3, Actual: 2\n",
      "Sample 1612 - Predicted: 5, Actual: 3\n",
      "Sample 1618 - Predicted: 7, Actual: 5\n",
      "Sample 1626 - Predicted: 5, Actual: 6\n",
      "Sample 1641 - Predicted: 8, Actual: 5\n",
      "Sample 1671 - Predicted: 9, Actual: 7\n",
      "Sample 1681 - Predicted: 7, Actual: 3\n",
      "Sample 1709 - Predicted: 3, Actual: 9\n",
      "Sample 1717 - Predicted: 0, Actual: 8\n",
      "Sample 1730 - Predicted: 8, Actual: 3\n",
      "Sample 1754 - Predicted: 2, Actual: 7\n",
      "Sample 1790 - Predicted: 9, Actual: 2\n",
      "Sample 1813 - Predicted: 2, Actual: 8\n",
      "Sample 1822 - Predicted: 5, Actual: 6\n",
      "Sample 1823 - Predicted: 3, Actual: 8\n",
      "Sample 1839 - Predicted: 3, Actual: 2\n",
      "Sample 1843 - Predicted: 2, Actual: 0\n",
      "Sample 1850 - Predicted: 3, Actual: 8\n",
      "Sample 1901 - Predicted: 4, Actual: 9\n",
      "Sample 1911 - Predicted: 6, Actual: 5\n",
      "Sample 1941 - Predicted: 4, Actual: 7\n",
      "Sample 1952 - Predicted: 8, Actual: 9\n",
      "Sample 1956 - Predicted: 9, Actual: 4\n",
      "Sample 1969 - Predicted: 0, Actual: 6\n",
      "Sample 1981 - Predicted: 4, Actual: 6\n",
      "Sample 1982 - Predicted: 8, Actual: 6\n",
      "Sample 1984 - Predicted: 0, Actual: 2\n",
      "Sample 2016 - Predicted: 2, Actual: 7\n",
      "Sample 2024 - Predicted: 9, Actual: 7\n",
      "Sample 2040 - Predicted: 6, Actual: 5\n",
      "Sample 2053 - Predicted: 9, Actual: 4\n",
      "Sample 2070 - Predicted: 9, Actual: 7\n",
      "Sample 2093 - Predicted: 2, Actual: 8\n",
      "Sample 2105 - Predicted: 8, Actual: 3\n",
      "Sample 2109 - Predicted: 9, Actual: 3\n",
      "Sample 2118 - Predicted: 9, Actual: 6\n",
      "Sample 2125 - Predicted: 9, Actual: 5\n",
      "Sample 2129 - Predicted: 7, Actual: 9\n",
      "Sample 2135 - Predicted: 1, Actual: 6\n",
      "Sample 2148 - Predicted: 9, Actual: 4\n",
      "Sample 2153 - Predicted: 5, Actual: 3\n",
      "Sample 2162 - Predicted: 9, Actual: 5\n",
      "Sample 2189 - Predicted: 1, Actual: 9\n",
      "Sample 2215 - Predicted: 5, Actual: 6\n",
      "Sample 2224 - Predicted: 8, Actual: 5\n",
      "Sample 2237 - Predicted: 8, Actual: 5\n",
      "Sample 2272 - Predicted: 6, Actual: 8\n",
      "Sample 2291 - Predicted: 8, Actual: 5\n",
      "Sample 2293 - Predicted: 0, Actual: 9\n",
      "Sample 2308 - Predicted: 5, Actual: 3\n",
      "Sample 2325 - Predicted: 1, Actual: 7\n",
      "Sample 2369 - Predicted: 8, Actual: 5\n",
      "Sample 2387 - Predicted: 1, Actual: 9\n",
      "Sample 2404 - Predicted: 2, Actual: 4\n",
      "Sample 2406 - Predicted: 1, Actual: 9\n",
      "Sample 2408 - Predicted: 8, Actual: 3\n",
      "Sample 2414 - Predicted: 4, Actual: 9\n",
      "Sample 2422 - Predicted: 0, Actual: 6\n",
      "Sample 2426 - Predicted: 4, Actual: 9\n",
      "Sample 2454 - Predicted: 8, Actual: 6\n",
      "Sample 2488 - Predicted: 8, Actual: 2\n",
      "Sample 2514 - Predicted: 9, Actual: 4\n",
      "Sample 2534 - Predicted: 5, Actual: 3\n",
      "Sample 2573 - Predicted: 3, Actual: 5\n",
      "Sample 2589 - Predicted: 0, Actual: 9\n",
      "Sample 2607 - Predicted: 1, Actual: 7\n",
      "Sample 2611 - Predicted: 8, Actual: 5\n",
      "Sample 2618 - Predicted: 5, Actual: 3\n",
      "Sample 2630 - Predicted: 9, Actual: 4\n",
      "Sample 2648 - Predicted: 5, Actual: 9\n",
      "Sample 2654 - Predicted: 1, Actual: 6\n",
      "Sample 2684 - Predicted: 1, Actual: 3\n",
      "Sample 2713 - Predicted: 8, Actual: 0\n",
      "Sample 2721 - Predicted: 5, Actual: 6\n",
      "Sample 2739 - Predicted: 4, Actual: 8\n",
      "Sample 2742 - Predicted: 8, Actual: 9\n",
      "Sample 2770 - Predicted: 6, Actual: 3\n",
      "Sample 2771 - Predicted: 1, Actual: 4\n",
      "Sample 2866 - Predicted: 4, Actual: 6\n",
      "Sample 2877 - Predicted: 7, Actual: 4\n",
      "Sample 2896 - Predicted: 0, Actual: 8\n",
      "Sample 2907 - Predicted: 9, Actual: 4\n",
      "Sample 2921 - Predicted: 8, Actual: 3\n",
      "Sample 2927 - Predicted: 2, Actual: 3\n",
      "Sample 2930 - Predicted: 7, Actual: 5\n",
      "Sample 2939 - Predicted: 5, Actual: 9\n",
      "Sample 2952 - Predicted: 5, Actual: 3\n",
      "Sample 2953 - Predicted: 5, Actual: 3\n",
      "Sample 2995 - Predicted: 5, Actual: 6\n",
      "Sample 3030 - Predicted: 8, Actual: 6\n",
      "Sample 3060 - Predicted: 7, Actual: 9\n",
      "Sample 3073 - Predicted: 7, Actual: 1\n",
      "Sample 3084 - Predicted: 9, Actual: 7\n",
      "Sample 3098 - Predicted: 9, Actual: 7\n",
      "Sample 3102 - Predicted: 9, Actual: 5\n",
      "Sample 3108 - Predicted: 5, Actual: 3\n",
      "Sample 3117 - Predicted: 9, Actual: 5\n",
      "Sample 3122 - Predicted: 2, Actual: 7\n",
      "Sample 3132 - Predicted: 3, Actual: 1\n",
      "Sample 3157 - Predicted: 7, Actual: 5\n",
      "Sample 3172 - Predicted: 9, Actual: 4\n",
      "Sample 3173 - Predicted: 2, Actual: 6\n",
      "Sample 3206 - Predicted: 3, Actual: 8\n",
      "Sample 3269 - Predicted: 0, Actual: 6\n",
      "Sample 3284 - Predicted: 7, Actual: 8\n",
      "Sample 3289 - Predicted: 9, Actual: 8\n",
      "Sample 3330 - Predicted: 3, Actual: 2\n",
      "Sample 3336 - Predicted: 7, Actual: 5\n",
      "Sample 3376 - Predicted: 9, Actual: 7\n",
      "Sample 3377 - Predicted: 9, Actual: 4\n",
      "Sample 3384 - Predicted: 5, Actual: 2\n",
      "Sample 3405 - Predicted: 9, Actual: 4\n",
      "Sample 3437 - Predicted: 9, Actual: 4\n",
      "Sample 3451 - Predicted: 3, Actual: 7\n",
      "Sample 3503 - Predicted: 1, Actual: 9\n",
      "Sample 3520 - Predicted: 4, Actual: 6\n",
      "Sample 3533 - Predicted: 9, Actual: 4\n",
      "Sample 3549 - Predicted: 2, Actual: 3\n",
      "Sample 3558 - Predicted: 0, Actual: 5\n",
      "Sample 3597 - Predicted: 3, Actual: 9\n",
      "Sample 3601 - Predicted: 6, Actual: 1\n",
      "Sample 3604 - Predicted: 0, Actual: 7\n",
      "Sample 3634 - Predicted: 2, Actual: 0\n",
      "Sample 3672 - Predicted: 2, Actual: 4\n",
      "Sample 3702 - Predicted: 4, Actual: 5\n",
      "Sample 3718 - Predicted: 9, Actual: 4\n",
      "Sample 3726 - Predicted: 9, Actual: 4\n",
      "Sample 3727 - Predicted: 4, Actual: 8\n",
      "Sample 3757 - Predicted: 3, Actual: 8\n",
      "Sample 3767 - Predicted: 2, Actual: 7\n",
      "Sample 3769 - Predicted: 9, Actual: 3\n",
      "Sample 3776 - Predicted: 8, Actual: 5\n",
      "Sample 3780 - Predicted: 6, Actual: 4\n",
      "Sample 3796 - Predicted: 8, Actual: 2\n",
      "Sample 3811 - Predicted: 3, Actual: 2\n",
      "Sample 3838 - Predicted: 1, Actual: 7\n",
      "Sample 3855 - Predicted: 0, Actual: 5\n",
      "Sample 3869 - Predicted: 4, Actual: 9\n",
      "Sample 3893 - Predicted: 3, Actual: 5\n",
      "Sample 3902 - Predicted: 3, Actual: 5\n",
      "Sample 3906 - Predicted: 3, Actual: 1\n",
      "Sample 3918 - Predicted: 8, Actual: 5\n",
      "Sample 3926 - Predicted: 3, Actual: 9\n",
      "Sample 3941 - Predicted: 0, Actual: 4\n",
      "Sample 3943 - Predicted: 5, Actual: 3\n",
      "Sample 3985 - Predicted: 4, Actual: 9\n",
      "Sample 4007 - Predicted: 4, Actual: 7\n",
      "Sample 4017 - Predicted: 9, Actual: 4\n",
      "Sample 4018 - Predicted: 5, Actual: 3\n",
      "Sample 4075 - Predicted: 3, Actual: 8\n",
      "Sample 4078 - Predicted: 2, Actual: 9\n",
      "Sample 4108 - Predicted: 9, Actual: 5\n",
      "Sample 4141 - Predicted: 1, Actual: 8\n",
      "Sample 4149 - Predicted: 3, Actual: 2\n",
      "Sample 4152 - Predicted: 6, Actual: 5\n",
      "Sample 4154 - Predicted: 4, Actual: 9\n",
      "Sample 4163 - Predicted: 0, Actual: 9\n",
      "Sample 4197 - Predicted: 2, Actual: 4\n",
      "Sample 4199 - Predicted: 9, Actual: 7\n",
      "Sample 4201 - Predicted: 2, Actual: 1\n",
      "Sample 4205 - Predicted: 6, Actual: 2\n",
      "Sample 4212 - Predicted: 3, Actual: 1\n",
      "Sample 4224 - Predicted: 7, Actual: 9\n",
      "Sample 4248 - Predicted: 8, Actual: 2\n",
      "Sample 4289 - Predicted: 7, Actual: 2\n",
      "Sample 4294 - Predicted: 5, Actual: 9\n",
      "Sample 4297 - Predicted: 1, Actual: 7\n",
      "Sample 4300 - Predicted: 9, Actual: 5\n",
      "Sample 4301 - Predicted: 8, Actual: 9\n",
      "Sample 4306 - Predicted: 7, Actual: 3\n",
      "Sample 4317 - Predicted: 9, Actual: 3\n",
      "Sample 4323 - Predicted: 3, Actual: 5\n",
      "Sample 4349 - Predicted: 4, Actual: 1\n",
      "Sample 4359 - Predicted: 9, Actual: 5\n",
      "Sample 4360 - Predicted: 3, Actual: 5\n",
      "Sample 4369 - Predicted: 4, Actual: 9\n",
      "Sample 4373 - Predicted: 2, Actual: 4\n",
      "Sample 4374 - Predicted: 8, Actual: 5\n",
      "Sample 4419 - Predicted: 1, Actual: 8\n",
      "Sample 4435 - Predicted: 7, Actual: 3\n",
      "Sample 4438 - Predicted: 7, Actual: 4\n",
      "Sample 4449 - Predicted: 0, Actual: 6\n",
      "Sample 4477 - Predicted: 6, Actual: 0\n",
      "Sample 4497 - Predicted: 7, Actual: 8\n",
      "Sample 4500 - Predicted: 1, Actual: 9\n",
      "Sample 4534 - Predicted: 7, Actual: 9\n",
      "Sample 4536 - Predicted: 5, Actual: 6\n",
      "Sample 4571 - Predicted: 8, Actual: 6\n",
      "Sample 4575 - Predicted: 2, Actual: 4\n",
      "Sample 4578 - Predicted: 9, Actual: 7\n",
      "Sample 4601 - Predicted: 4, Actual: 8\n",
      "Sample 4639 - Predicted: 3, Actual: 8\n",
      "Sample 4690 - Predicted: 9, Actual: 7\n",
      "Sample 4699 - Predicted: 1, Actual: 6\n",
      "Sample 4731 - Predicted: 7, Actual: 8\n",
      "Sample 4738 - Predicted: 5, Actual: 4\n",
      "Sample 4740 - Predicted: 9, Actual: 3\n",
      "Sample 4751 - Predicted: 6, Actual: 4\n",
      "Sample 4761 - Predicted: 4, Actual: 9\n",
      "Sample 4807 - Predicted: 5, Actual: 8\n",
      "Sample 4808 - Predicted: 5, Actual: 3\n",
      "Sample 4814 - Predicted: 8, Actual: 6\n",
      "Sample 4823 - Predicted: 4, Actual: 9\n",
      "Sample 4833 - Predicted: 2, Actual: 3\n",
      "Sample 4837 - Predicted: 1, Actual: 7\n",
      "Sample 4852 - Predicted: 6, Actual: 8\n",
      "Sample 4860 - Predicted: 9, Actual: 4\n",
      "Sample 4874 - Predicted: 5, Actual: 9\n",
      "Sample 4880 - Predicted: 8, Actual: 0\n",
      "Sample 4886 - Predicted: 1, Actual: 7\n",
      "Sample 4890 - Predicted: 6, Actual: 8\n",
      "Sample 4896 - Predicted: 9, Actual: 4\n",
      "Sample 4956 - Predicted: 4, Actual: 8\n",
      "Sample 4966 - Predicted: 9, Actual: 7\n",
      "Sample 4969 - Predicted: 3, Actual: 2\n",
      "Sample 4987 - Predicted: 6, Actual: 4\n",
      "Sample 4990 - Predicted: 2, Actual: 3\n",
      "Sample 4995 - Predicted: 3, Actual: 2\n",
      "Sample 5074 - Predicted: 9, Actual: 3\n",
      "Sample 5183 - Predicted: 4, Actual: 8\n",
      "Sample 5201 - Predicted: 9, Actual: 4\n",
      "Sample 5217 - Predicted: 8, Actual: 2\n",
      "Sample 5246 - Predicted: 2, Actual: 7\n",
      "Sample 5331 - Predicted: 6, Actual: 1\n",
      "Sample 5409 - Predicted: 6, Actual: 4\n",
      "Sample 5464 - Predicted: 7, Actual: 4\n",
      "Sample 5495 - Predicted: 3, Actual: 8\n",
      "Sample 5600 - Predicted: 9, Actual: 7\n",
      "Sample 5634 - Predicted: 8, Actual: 2\n",
      "Sample 5642 - Predicted: 8, Actual: 1\n",
      "Sample 5676 - Predicted: 7, Actual: 4\n",
      "Sample 5677 - Predicted: 2, Actual: 4\n",
      "Sample 5696 - Predicted: 2, Actual: 4\n",
      "Sample 5734 - Predicted: 2, Actual: 3\n",
      "Sample 5749 - Predicted: 6, Actual: 8\n",
      "Sample 5832 - Predicted: 9, Actual: 4\n",
      "Sample 5835 - Predicted: 9, Actual: 7\n",
      "Sample 5851 - Predicted: 8, Actual: 4\n",
      "Sample 5887 - Predicted: 0, Actual: 7\n",
      "Sample 5888 - Predicted: 0, Actual: 4\n",
      "Sample 5926 - Predicted: 9, Actual: 4\n",
      "Sample 5936 - Predicted: 9, Actual: 4\n",
      "Sample 5937 - Predicted: 3, Actual: 5\n",
      "Sample 5955 - Predicted: 8, Actual: 3\n",
      "Sample 5973 - Predicted: 8, Actual: 3\n",
      "Sample 6011 - Predicted: 8, Actual: 3\n",
      "Sample 6023 - Predicted: 8, Actual: 3\n",
      "Sample 6026 - Predicted: 9, Actual: 7\n",
      "Sample 6030 - Predicted: 2, Actual: 3\n",
      "Sample 6035 - Predicted: 8, Actual: 2\n",
      "Sample 6037 - Predicted: 9, Actual: 4\n",
      "Sample 6046 - Predicted: 8, Actual: 3\n",
      "Sample 6059 - Predicted: 8, Actual: 3\n",
      "Sample 6065 - Predicted: 8, Actual: 3\n",
      "Sample 6071 - Predicted: 3, Actual: 9\n",
      "Sample 6091 - Predicted: 3, Actual: 9\n",
      "Sample 6093 - Predicted: 8, Actual: 2\n",
      "Sample 6160 - Predicted: 8, Actual: 3\n",
      "Sample 6165 - Predicted: 8, Actual: 5\n",
      "Sample 6166 - Predicted: 3, Actual: 9\n",
      "Sample 6168 - Predicted: 3, Actual: 9\n",
      "Sample 6172 - Predicted: 5, Actual: 9\n",
      "Sample 6173 - Predicted: 8, Actual: 9\n",
      "Sample 6347 - Predicted: 6, Actual: 8\n",
      "Sample 6505 - Predicted: 0, Actual: 9\n",
      "Sample 6528 - Predicted: 4, Actual: 2\n",
      "Sample 6553 - Predicted: 9, Actual: 4\n",
      "Sample 6555 - Predicted: 9, Actual: 8\n",
      "Sample 6558 - Predicted: 2, Actual: 6\n",
      "Sample 6560 - Predicted: 8, Actual: 9\n",
      "Sample 6577 - Predicted: 1, Actual: 7\n",
      "Sample 6597 - Predicted: 7, Actual: 0\n",
      "Sample 6598 - Predicted: 3, Actual: 5\n",
      "Sample 6599 - Predicted: 9, Actual: 7\n",
      "Sample 6632 - Predicted: 5, Actual: 9\n",
      "Sample 6636 - Predicted: 8, Actual: 3\n",
      "Sample 6645 - Predicted: 8, Actual: 2\n",
      "Sample 6651 - Predicted: 5, Actual: 0\n",
      "Sample 6662 - Predicted: 3, Actual: 7\n",
      "Sample 6690 - Predicted: 5, Actual: 3\n",
      "Sample 6740 - Predicted: 0, Actual: 9\n",
      "Sample 6744 - Predicted: 8, Actual: 2\n",
      "Sample 6746 - Predicted: 4, Actual: 5\n",
      "Sample 6755 - Predicted: 9, Actual: 8\n",
      "Sample 6759 - Predicted: 6, Actual: 4\n",
      "Sample 6783 - Predicted: 2, Actual: 1\n",
      "Sample 6847 - Predicted: 4, Actual: 6\n",
      "Sample 6872 - Predicted: 8, Actual: 4\n",
      "Sample 6926 - Predicted: 4, Actual: 6\n",
      "Sample 7178 - Predicted: 8, Actual: 5\n",
      "Sample 7208 - Predicted: 3, Actual: 8\n",
      "Sample 7210 - Predicted: 8, Actual: 6\n",
      "Sample 7216 - Predicted: 6, Actual: 0\n",
      "Sample 7233 - Predicted: 8, Actual: 3\n",
      "Sample 7249 - Predicted: 4, Actual: 2\n",
      "Sample 7259 - Predicted: 2, Actual: 8\n",
      "Sample 7338 - Predicted: 9, Actual: 4\n",
      "Sample 7394 - Predicted: 9, Actual: 4\n",
      "Sample 7432 - Predicted: 2, Actual: 7\n",
      "Sample 7434 - Predicted: 3, Actual: 4\n",
      "Sample 7457 - Predicted: 7, Actual: 2\n",
      "Sample 7492 - Predicted: 7, Actual: 2\n",
      "Sample 7511 - Predicted: 8, Actual: 5\n",
      "Sample 7539 - Predicted: 8, Actual: 2\n",
      "Sample 7551 - Predicted: 5, Actual: 3\n",
      "Sample 7552 - Predicted: 9, Actual: 8\n",
      "Sample 7602 - Predicted: 8, Actual: 5\n",
      "Sample 7619 - Predicted: 1, Actual: 2\n",
      "Sample 7742 - Predicted: 8, Actual: 5\n",
      "Sample 7797 - Predicted: 8, Actual: 5\n",
      "Sample 7812 - Predicted: 8, Actual: 1\n",
      "Sample 7822 - Predicted: 8, Actual: 1\n",
      "Sample 7842 - Predicted: 6, Actual: 5\n",
      "Sample 7849 - Predicted: 2, Actual: 3\n",
      "Sample 7850 - Predicted: 6, Actual: 5\n",
      "Sample 7858 - Predicted: 2, Actual: 3\n",
      "Sample 7902 - Predicted: 9, Actual: 7\n",
      "Sample 7905 - Predicted: 2, Actual: 3\n",
      "Sample 7921 - Predicted: 6, Actual: 8\n",
      "Sample 8020 - Predicted: 8, Actual: 1\n",
      "Sample 8061 - Predicted: 9, Actual: 4\n",
      "Sample 8062 - Predicted: 8, Actual: 5\n",
      "Sample 8091 - Predicted: 8, Actual: 2\n",
      "Sample 8094 - Predicted: 8, Actual: 2\n",
      "Sample 8112 - Predicted: 8, Actual: 2\n",
      "Sample 8243 - Predicted: 8, Actual: 0\n",
      "Sample 8245 - Predicted: 8, Actual: 2\n",
      "Sample 8246 - Predicted: 9, Actual: 3\n",
      "Sample 8277 - Predicted: 9, Actual: 3\n",
      "Sample 8290 - Predicted: 8, Actual: 3\n",
      "Sample 8292 - Predicted: 8, Actual: 2\n",
      "Sample 8294 - Predicted: 9, Actual: 8\n",
      "Sample 8304 - Predicted: 3, Actual: 7\n",
      "Sample 8308 - Predicted: 9, Actual: 3\n",
      "Sample 8320 - Predicted: 7, Actual: 2\n",
      "Sample 8339 - Predicted: 6, Actual: 8\n",
      "Sample 8374 - Predicted: 8, Actual: 9\n",
      "Sample 8376 - Predicted: 4, Actual: 1\n",
      "Sample 8406 - Predicted: 9, Actual: 4\n",
      "Sample 8408 - Predicted: 6, Actual: 8\n",
      "Sample 8416 - Predicted: 7, Actual: 4\n",
      "Sample 8430 - Predicted: 5, Actual: 3\n",
      "Sample 8453 - Predicted: 3, Actual: 5\n",
      "Sample 8502 - Predicted: 8, Actual: 5\n",
      "Sample 8520 - Predicted: 9, Actual: 4\n",
      "Sample 8527 - Predicted: 9, Actual: 4\n",
      "Sample 8584 - Predicted: 3, Actual: 2\n",
      "Sample 8912 - Predicted: 1, Actual: 8\n",
      "Sample 9009 - Predicted: 2, Actual: 7\n",
      "Sample 9015 - Predicted: 2, Actual: 7\n",
      "Sample 9016 - Predicted: 8, Actual: 0\n",
      "Sample 9019 - Predicted: 2, Actual: 7\n",
      "Sample 9024 - Predicted: 2, Actual: 7\n",
      "Sample 9036 - Predicted: 2, Actual: 7\n",
      "Sample 9046 - Predicted: 3, Actual: 2\n",
      "Sample 9128 - Predicted: 7, Actual: 4\n",
      "Sample 9209 - Predicted: 8, Actual: 2\n",
      "Sample 9316 - Predicted: 3, Actual: 8\n",
      "Sample 9422 - Predicted: 3, Actual: 5\n",
      "Sample 9512 - Predicted: 9, Actual: 4\n",
      "Sample 9587 - Predicted: 4, Actual: 9\n",
      "Sample 9624 - Predicted: 8, Actual: 3\n",
      "Sample 9634 - Predicted: 2, Actual: 0\n",
      "Sample 9636 - Predicted: 5, Actual: 3\n",
      "Sample 9716 - Predicted: 3, Actual: 2\n",
      "Sample 9719 - Predicted: 0, Actual: 5\n",
      "Sample 9729 - Predicted: 6, Actual: 5\n",
      "Sample 9732 - Predicted: 3, Actual: 8\n",
      "Sample 9744 - Predicted: 1, Actual: 8\n",
      "Sample 9745 - Predicted: 8, Actual: 4\n",
      "Sample 9749 - Predicted: 6, Actual: 5\n",
      "Sample 9751 - Predicted: 0, Actual: 2\n",
      "Sample 9764 - Predicted: 3, Actual: 4\n",
      "Sample 9768 - Predicted: 9, Actual: 2\n",
      "Sample 9770 - Predicted: 0, Actual: 5\n",
      "Sample 9777 - Predicted: 0, Actual: 5\n",
      "Sample 9779 - Predicted: 0, Actual: 2\n",
      "Sample 9792 - Predicted: 1, Actual: 4\n",
      "Sample 9839 - Predicted: 3, Actual: 2\n",
      "Sample 9858 - Predicted: 3, Actual: 6\n",
      "Sample 9888 - Predicted: 8, Actual: 6\n",
      "Sample 9892 - Predicted: 5, Actual: 8\n",
      "Sample 9940 - Predicted: 8, Actual: 6\n",
      "Sample 9941 - Predicted: 6, Actual: 5\n",
      "Sample 9943 - Predicted: 5, Actual: 3\n",
      "Sample 9944 - Predicted: 9, Actual: 3\n",
      "Sample 9953 - Predicted: 2, Actual: 6\n",
      "Sample 9980 - Predicted: 3, Actual: 2\n",
      "Sample 9982 - Predicted: 8, Actual: 5\n",
      "Accuracy: 0.9499\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    return exp_a / sum_exp_a\n",
    "\n",
    "def predict(network, x):\n",
    "    \"\"\"推理方法\n",
    "\n",
    "    Args:\n",
    "        network: dict，包含了所有 W、B 等权重参数的“神经网络模型”；\n",
    "        x: nparray，输入数据，此处是图片的像素数组表示；\n",
    "    Returns:\n",
    "        y: nparray，推理结果，此处是图片分别为 0 ~ 9 的概率；\n",
    "    \"\"\"\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']    # 第 1 层、第 2 层、输出层分别的权重\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']    # 第 1 层、第 2 层、输出层分别的偏置\n",
    "    a1 = np.dot(x, W1) + b1                                     # 第 1 层加权和\n",
    "    z1 = relu(a1)                                               # 第 1 层加权和经过 relu 激活函数转换的结果\n",
    "    a2 = np.dot(z1, W2) + b2                                    # 第 2 层加权和\n",
    "    z2 = relu(a2)                                               # 第 2 层加权和经过 relu 激活函数转换的结果\n",
    "    a3 = np.dot(z2, W3) + b3                                    # 输出层加权和\n",
    "    y = softmax(a3)                                             # 输出层加权和经过 softmax 激活函数转换的结果\n",
    "    return y\n",
    "\n",
    "# 使用 network 模型进行推理测试\n",
    "network = init_network()\n",
    "\n",
    "print('Total number of samples:', len(x_test))\n",
    "\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x_test)):\n",
    "    y = predict(network, x_test.iloc[i])\n",
    "    # 获取概率最高的元素的索引\n",
    "    p = np.argmax(y)\n",
    "    # 判断是否与标签相符\n",
    "    if p == int(t_test.iloc[i]):\n",
    "        accuracy_cnt += 1\n",
    "    else:\n",
    "        print(f\"Sample {i} - Predicted: {p}, Actual: {t_test.iloc[i]}\")\n",
    "\n",
    "print(\"Accuracy:\", str(float(accuracy_cnt) / len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**工程完整信息与更多演示：**\n",
    "- 博主个人主页：[三余知行官方网站](https://threefish.site/trend)\n",
    "- GitHub Repo：[ThreeFish-AI/deep-learning](https://github.com/ThreeFish-AI/deep-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
